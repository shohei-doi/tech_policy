[
  {
    "objectID": "machine_learning.html",
    "href": "machine_learning.html",
    "title": "人工知能の機械学習",
    "section": "",
    "text": "警告\n\n\n\n日進月歩の分野なので、本章の内容はすぐに古いものになる（or既にそうであるかもしれない）点に注意。\n\n\nビッグデータは魅力的な資源（材料）だが、有効な利用法（調理法）があって初めて価値を持つ。\n\\(\\leadsto\\)近年のデータ科学における2つの変革\n\n機械学習：データから一定のパターンを機械（パソコン）が学習し、予測をする。\n因果推論：データから因果関係（因果効果）を学習する。\n\n\\(\\leadsto\\)いわゆる（最近において）人工知能と呼ばれるものは機械学習（予測）\n\n現在は第3次人工知能ブームと言われている。\nクオリティが高いがゆえに、あたかも機械が人間のように思考しているように見えてしまう。\n自然言語処理に関するタスクSuperGLUEでは人間を越えている。\n\n\n\n\n\n生成 (generative) AI：ある情報から、別の情報を出力するモデル\n\n大規模言語モデル (large language model: LLM)：大量のテキストを使い、巨大なモデルを学習した生成AI\n\nChatGPT、Google Bard、Microsoft Bing AIなど\nGPT=Generative Pre-trained Trensformer\nまずは、OpenAIのPlaygroundで遊んでみよう。\n\n画像生成の性能も向上、Vision and Languageの発展\n\nDALL·E 2 、midjourney 、stable difffusion など\n\n\n生成モデルも実は予測の組み合わせである。\n\nDeepL\\(\\leadsto\\)ある言語の文章から他の言語の文章を予測する。\nチャットbot、文書要約、コード生成\\(\\leadsto\\)ある文章から返答、要約、次に来る文章を予測する。\nAmazonやNetflixの推薦\\(\\leadsto\\)これまでの購入履歴やウォッチリストから次に購入する商品を予測する。\n学習過程にテキストデータを含めることで、テキストから画像生成できる (vision and language) 。\n\n代表的な機械学習の分類\n\n教師あり学習：特徴量 (feature) から対象を予測する。\n教師なし学習：多様な特徴量から重要なものを抽出する。\n強化学習：フィードバックを通じて最適な方策 (policy) を発見する。\n\n\\(\\leadsto\\)これらの概要を理解し、生成AIが何をしているかを理解する。"
  },
  {
    "objectID": "machine_learning.html#はじめに",
    "href": "machine_learning.html#はじめに",
    "title": "人工知能の機械学習",
    "section": "",
    "text": "警告\n\n\n\n日進月歩の分野なので、本章の内容はすぐに古いものになる（or既にそうであるかもしれない）点に注意。\n\n\nビッグデータは魅力的な資源（材料）だが、有効な利用法（調理法）があって初めて価値を持つ。\n\\(\\leadsto\\)近年のデータ科学における2つの変革\n\n機械学習：データから一定のパターンを機械（パソコン）が学習し、予測をする。\n因果推論：データから因果関係（因果効果）を学習する。\n\n\\(\\leadsto\\)いわゆる（最近において）人工知能と呼ばれるものは機械学習（予測）\n\n現在は第3次人工知能ブームと言われている。\nクオリティが高いがゆえに、あたかも機械が人間のように思考しているように見えてしまう。\n自然言語処理に関するタスクSuperGLUEでは人間を越えている。\n\n\n\n\n\n生成 (generative) AI：ある情報から、別の情報を出力するモデル\n\n大規模言語モデル (large language model: LLM)：大量のテキストを使い、巨大なモデルを学習した生成AI\n\nChatGPT、Google Bard、Microsoft Bing AIなど\nGPT=Generative Pre-trained Trensformer\nまずは、OpenAIのPlaygroundで遊んでみよう。\n\n画像生成の性能も向上、Vision and Languageの発展\n\nDALL·E 2 、midjourney 、stable difffusion など\n\n\n生成モデルも実は予測の組み合わせである。\n\nDeepL\\(\\leadsto\\)ある言語の文章から他の言語の文章を予測する。\nチャットbot、文書要約、コード生成\\(\\leadsto\\)ある文章から返答、要約、次に来る文章を予測する。\nAmazonやNetflixの推薦\\(\\leadsto\\)これまでの購入履歴やウォッチリストから次に購入する商品を予測する。\n学習過程にテキストデータを含めることで、テキストから画像生成できる (vision and language) 。\n\n代表的な機械学習の分類\n\n教師あり学習：特徴量 (feature) から対象を予測する。\n教師なし学習：多様な特徴量から重要なものを抽出する。\n強化学習：フィードバックを通じて最適な方策 (policy) を発見する。\n\n\\(\\leadsto\\)これらの概要を理解し、生成AIが何をしているかを理解する。"
  },
  {
    "objectID": "machine_learning.html#教師あり学習",
    "href": "machine_learning.html#教師あり学習",
    "title": "人工知能の機械学習",
    "section": "1 教師あり学習",
    "text": "1 教師あり学習\n教師あり学習とは、機械に人間の判断のパターンを学習させ、模倣できるようにすること。\n\\(\\leadsto\\)言い換えれば、予測 (prediction) というタスクを実行できるように訓練する。\n\n写真とその内容のペアのデータを機械に覚えさせる。\n住宅の情報（間取り、最寄り駅までの距離……etc）と価格を機械に覚えさせる。\n\n\n\n\n教師あり学習のイメージ\n\n\n\\(\\leadsto\\)ある情報を入力すると、それに対応する情報を出力する。\n\n入力情報に対応する出力（正解）を人間が判断するアノテーションが重要になる。\n\n\n1.1 回帰分析\nシンプルで、広く使われている教師あり学習の手法として回帰分析 (regression analysis) がある。\n\n例えば、北海道の中古マンション価格の教師あり学習を行ってみる。\n\n\n\n\n\n\n\\[\n\\textrm{価格} = 335.58 + 11.84 \\times \\textrm{広さ}\n\\]\n最小二乗法 (ordinary least squares: OLS) はデータとの誤差が最も小さくなる直線を計算する。\n\n予測値を一次関数（直線）で予測する。\n\n\\[\ni\\textrm{の予測値} = \\hat{y}_i = \\underbrace{\\hat{\\alpha}}_{\\textrm{切片 (intercept)}}\n+ \\underbrace{\\hat{\\beta}}_{\\textrm{傾き (slope)}} x_i\n\\]\n\n\\(i\\)は個体ごとに異なる値を取るということを意味している。\n上手く予測できるような\\(\\hat{\\alpha}, \\hat{\\beta}\\)をデータから求める（学習する）。\n真の値と予測値のズレ、誤差 (error) が小さい方がいいはず。\n\n\\[\ni\\textrm{の予測誤差} = i\\textrm{の真の値} - i\\textrm{の予測値} = y_i - \\hat{y}_i\n\\]\n\nズレはプラスにもマイナスにもなるので、プラスの値しか取らない距離や面積に変換する。\n通常は誤差を二乗して、面積にする。\n\n\\[\ni\\textrm{の予測誤差の二乗} = i\\textrm{の真の値} - i\\textrm{の予測値} = (y_i - \\hat{y}_i)^2\n\\]\n\n個々の誤差をデータ全体について計算し、合計する。\n\n\\[\ni\\textrm{の予測誤差の二乗の合計} = (y_1 - \\hat{y}_1)^2 + (y_2 - \\hat{y}_2)^2 + \\cdots\n\\]\n\\(\\leadsto\\)これを最小にする\\(\\hat{\\alpha}, \\hat{\\beta}\\)をデータから求める！（パソコンが計算してくれる）11 最適化（偏微分係数が0となる値を求める）によって明示的に解くことができる。\n\n\\(\\hat{\\alpha}, \\hat{\\beta}\\)は\\(\\hat{y}_i\\)の中に入っていることに注意。\n\n\n\n\n\n予測に使う情報（特徴量）は1つである必要はない。\n\\[\n\\textrm{価格} = 396.27 + 12.50 \\times \\textrm{広さ} -10.57 \\times \\textrm{距離}\n\\]\n\nパターンを学習しているだけであり、機械がマンションについて理解しているわけではない。\n\n予測対象がカテゴリーの場合はどうするのか？\n\n機械学習の代表的なデータセットにタイタニック号の乗客データがある。\nこのときの予測対象は乗客が生存したかどうかというカテゴリー\n\n\\(\\leadsto\\)ロジスティック関数（シグモイド関数）を使って変形すると、0から1の間に収まる。\n\n\n\n\n\n\n\n1.2 決定木\n回帰分析以外の代表的な教師あり学習の手法として決定木 (decision tree) がある。\n\n\n\n決定木のイメージ\n\n\n\\(\\leadsto\\)弱い決定木をたくさん集めたランダム・フォレスト（やその発展形2）がよく使われている。2 XGBoostやLightGBMなど。\n\n三人寄れば文殊の知恵？　陪審定理？\n\n\n\n1.3 深層学習\n深層学習 (deep learning) は深層ニューラル・ネットワーク (deep neural network: DNN) とも呼ばれる。\n\\(\\leadsto\\)もともとは人間のニューロンをマシン上で再現すれば人工知能ができるかもという期待\n\n閾値を超えると発火して信号を送信する。\n\n\n\n\n\n\n\\(\\leadsto\\)回帰分析をニューロンとして見て3、これをたくさん作る。3 厳密に言えば、活性化関数を挟む。\n\n\n\nロジスティック回帰のイメージ\n\n\n\n\n\n深層ニューラル・ネットワークのイメージ\n\n\nなぜ深層学習はすごいのか？\n\n隠れ層を増やせば増やすほど柔軟な予測ができる。\n\nパラメータの数（隠れ層の数に比例）\\(\\approx\\)モデルのサイズ\n例えば\\[\\hat{y}_i = \\hat{\\alpha} + \\hat{\\beta} x_i\\]のパラメータの数は2\n\n特徴量を人間が作らなくてよい。\n\nむしろ、重要な特徴量がなにかを学習する（表現学習）。\n\n学習済みモデルを使える。\n\nタスクに応じて出力側を再学習（ファイン・チューニング）する。\nGPT=Generative Pre-trained Trensformer\n\n様々な形式のデータ（テキスト、画像、音声……）を同じ枠組みで分析できる。\n\nvision and languageなどマルチモーダルなモデルの開発\n\n\n\\(\\leadsto\\)生成AI（LLM含む）は与えられた単語の列から、次に来そうな、もっともらしい単語を予測している（だけ）！\n\n\n\nLLMによる文書生成のイメージ\n\n\n\n同じ入力に対して同じ回答をしないように、ある程度ランダムに予測をしている。\n\nGPTにおけるtemparatureはランダム度合いを指定している。\n\n人工知能の獲得か？（例、中国語の部屋）\n\n\n\n1.4 プロンプト・エンジニアリング\nChatGPTなどの最近のLLMがすごいのは、タスクも指示するだけでよいこと。\n\n翻訳、要約、質疑応答などのタスクごとにモデルを作らなくて良い。\n\n\\(\\leadsto\\)入力する指示文（プロンプト）をどのようにするのかが重要。\n\nプロンプトの書き方を工夫することをプロンプト・エンジニアリングなどと呼ぶ。\nいくつかの具体例を提示すると、性能が良くなる、安定するfew shot learningという現象（？）\n\n\n\n1.5 拡散モデル\n拡散モデル：画像にノイズを追加していって、それを取り除くプロセスを学習\n\n\n\n拡散モデルのイメージ\n\n\n\n\n\n拡散モデルのイメージ\n\n\n\\(\\leadsto\\)テキストからの画像生成もテキスト→画像の予測を行っている。"
  },
  {
    "objectID": "machine_learning.html#教師なし学習",
    "href": "machine_learning.html#教師なし学習",
    "title": "人工知能の機械学習",
    "section": "2 教師なし学習",
    "text": "2 教師なし学習\n数値ではない文書データをどのようにデータ分析するのか？\n\nシンプルな方法はbag of words（単語の出現頻度を特徴量とする）アプローチ\n\n\\(\\leadsto\\)教師なし学習によってデータから特徴量を抽出する。\n\n2.1 単語埋め込み\n単語埋め込み (word embedding)：単語を低次元空間のベクトルに変換する\n\\(\\leadsto\\)単語のベクトル（位置）\\(\\approx\\)意味？\n\n\n\n単語埋め込みのイメージ\n\n\n\n単語の意味は周辺の単語によって決まるはず。\n\n\n\n\n単語埋め込みの学習のイメージ\n\n\n\\(\\leadsto\\)周辺の単語をうまく予測できるベクトルを学習する。\n\n画像も同様に埋め込むことで、テキスト→画像の予測が可能となる。\n\n\n\n2.2 自己注意機構\n近年の自然言語処理の飛躍的発展のキーはTransformer(Vaswani ほか 2017)の登場44 Transformerを提案したのはGoogleの研究者たち。\n\nBERT=Bidirectional Encoder Representations from Transformers\nGPT=Generative Pre-trained Trensformer\n\n\n\n\nTransformerベースのLLM\n\n\n\\(\\leadsto\\)特に自己注意機構 (self-attention mechanism) が重要（と言われている）\n\nある単語を処理する際に、他のどの単語に注目すればよいのかを学習する。\n“Attention is all you need”(Vaswani ほか 2017)\n\n\n\n\n自己注意機構のイメージ\n\n\n\n離れた単語も踏まえた学習ができる。\n学習速度が高速になる。5\n\n5 並列化が可能になるため。"
  },
  {
    "objectID": "machine_learning.html#強化学習",
    "href": "machine_learning.html#強化学習",
    "title": "人工知能の機械学習",
    "section": "3 強化学習",
    "text": "3 強化学習\n一部のモデルでは強化学習を用いて、更に性能を向上させている。\n\n例、GPT-3やそれ以上のベースと考えられているInstructGPT\n\n強化学習では機械が最適なアクションを見つける。\n\nデータからパターンを発見するわけではない。\nエージェントが状態→行動→環境→報酬・状態を繰り返し、報酬を大きくする行動を発見する。\n\n\n\n\n強化学習のイメージ\n\n\n\n3.1 AlphaGo\nAlphaGoは強化学習で囲碁のアルゴリズムを学習し2016年に世界トップ棋士に勝利\n\n初期設定として実際の棋譜データから学習したアルゴリズムを使用\n2つのエージェント（機械）が対戦する中で大量にデータを生成し、学習\n\n\n\n\nSilver ほか (2016)\n\n\n\n\n3.2 人間のフィードバック\nInstructGPTでは人間のフィードバックからの強化学習 (Reinforcement Learning from Human Feedback: RLHF) を用いている。\n\nプロンプトと（人間の作った）回答のデータから教師あり学習\n1で作ったモデルの回答結果と人間の採点結果のデータから教師あり学習\n1と2のモデルを使ってプロンプト→回答→採点の強化学習\n\n\n\n\nAligning language models to follow instructions"
  },
  {
    "objectID": "machine_learning.html#人工知能の社会的課題",
    "href": "machine_learning.html#人工知能の社会的課題",
    "title": "人工知能の機械学習",
    "section": "4 人工知能の社会的課題",
    "text": "4 人工知能の社会的課題\nあらゆる技術がそうであるように、新しい技術の登場、急速な普及は様々な問題を引き起こしうる。\n\nG7広島サミットで生成AIに関するルールを策定する広島AIプロセスの立ち上げに合意\n\n\n4.1 人工知能の使い方\n\n4.1.1 人工知能の悪用\nAIを悪用\\(\\leadsto\\)偽の情報を作り、拡散\n\n文書生成 \\(\\leadsto\\) フェイクニュース\n物体検出 & 画像生成 \\(\\leadsto\\) Deep Fake\n\n\\(\\leadsto\\)Deep Fakeはオンラインの画像や映像を加工\\(\\leadsto\\)フェイクポルノなど深刻な被害の可能性\n\n\n\nDeep Fakeの例\n\n\n\nちなみに、スクリーンショットの捏造は人工知能を使わなくても簡単にできる。\n\nどんな技術も悪用しようと思えばできる\\(\\leadsto\\)（個人的に）重要なのは、悪用よりも誤用\n\n\n4.1.2 人工知能の誤用\n統計的差別 (statistical discrimination) ：個人の属性（属する集団）に基づく差別\n\n学歴、性別、人種などで就職活動、賃貸契約、判決が異なる。\n\n白人っぽい名前の履歴書と黒人っぽい名前の履歴書だと前者のほうが選考を通りやすい(Agan と Starr 2018)。\n特に犯罪歴の記入要求を禁止 (ban the bpx) の後に顕著。\n\n\n\n\n\nAgan と Starr (2018)\n\n\n\\(\\leadsto\\)機械学習はあくまで「人間を模倣」するので、人間に（無意識でも）差別があれば、機械はそれを学習する。\nアメリカの一部の州では保釈や刑期を決定する際にCOMPASというシステムでリスク評価を行っていた。\n\n黒人では「再犯する」と予測されたが「再犯しなかった」という間違いが多かった。\n白人では「再犯しない」と予測されたが「再犯した」という間違いが多かった。\n\n\n\n\nCOMPASSによる再犯予測\n\n\n学習に用いるデータが偏っている\\(\\leadsto\\)予測も偏る。\n\n\n\n偏ったデータによる学習\n\n\n\\(\\leadsto\\)公平性のある機械学習を行う必要がある。\n敵対的攻撃 (adversarial attack) ：あえてAIを騙すような情報入力\n\n\n\n敵対的攻撃\n\n\nChatGPTなどで指摘されているのは幻覚 (hallucination) と呼ばれる現象\n\n正しくない回答をあたかも正しいものと堂々と提示する。\n\n意図せざる形での著作権侵害や個人情報流出も？\n\n学習に使用されたデータがほとんどそのまま出力される可能性\n\n\\(\\leadsto\\)AIだからといって客観的であるわけでも、常識的であるわけでもない。\n\n特に深層学習の中身はブラックボックスであり、説明可能性に欠けている。\n回帰分析や決定木は分かりやすい。\n\n\n\n4.1.3 人工知能と倫理\nAI倫理、公平性のあるAIなどが必要\n\\(\\leadsto\\)AIが守るべき倫理、公平性とは？\n自動運転車がトロッコ問題に遭遇したとき、どうすべきなのか？\nモラル・マシンというアンケートに答えることで、どのような命を重視するのかが分かる。\n\n\n\n\n\n「審査を始める」を押す。\n直進する場合は左の絵を、曲がる場合は右の絵をクリックする。\n\nドクロマークがついている人が死んでしまうとする。\n\n\n\n\n\nAwad ほか (2018)\n\n\n倫理観は国ごとに異なる。\n\n\n\nAI倫理観の地域ごとの違い\n\n\n日本の場合は、\n\nお年寄りを助け、\nより多くの人を助けるわけではなく、\n歩行者を助ける\n\n傾向にあるらしい。\n\n人工知能は人間に代わって倫理的判断を行うわけではない。\n\n人工知能に期待する倫理も人々、国々の間で同じではない。\n\n人工知能は誤作動も起こりうる。\n\n\\(\\leadsto\\)人工知能の責任はどこにあるのか？\n\n生成AI（Generative AI）の倫理的・法的・社会的課題（ELSI）論点の概観：2023年3月版（大阪大学）\n\n\n\n4.1.4 人工知能と兵器\n無人兵器とAI技術の発展は自律型致死兵器システム (Lethal Autonomous Weapons Systems: LAWS) の可能性を現実のものとしつつある。\n\n人間の代わりに戦闘をさせることで人命の損失を減らせる／戦争やテロリズムが起こりやすくなる？\n人道法の違反（文民の殺害など）を起こす？\n\n誤作動だけでなく、現在のAI技術ではAIの判断を人間が理解できない可能性\n\n\n\\(\\leadsto\\)LAWS規制に関する議論の指針が2019年に定まったばかり。\n\n\n\n4.2 人工知能と社会\n\n4.2.1 人工知能と政治\nAIと民主主義の関わりに着目されつつある？\n\nAIが人間に代わって政策を決定する。\nAIが個人の思考を学習して人間の代わりに政治（議論や投票……）をする。\nAIが議論や情報収集をアシストする。\n\n科学技術を巡って展開される政治がある。\n\\(\\leadsto\\)なぜ、特定の技術がグローバル・スタンダードとして支配的になるのだろうか？\n\n\n\n\n\n\nWindows vs Mac\n\n\n\n\n\n\n\nQWERTY配列\n\n\n\n\n\n\n\n\n\nVHS vs Beta\n\n\n\n\n\n\n\nエアバスvsボーイング\n\n\n\n\n\n\n\n\n\n左側通行vs右側通行\n\n\n\n\n\n\n\n摂氏vs華氏\n\n\n\n\n\nネットワーク外部性：利用者が多いと、利用するメリットが増える。\n\\(\\leadsto\\)ある程度の規模の人々（クリティカル・マス）がその製品や技術を用いる\\(\\leadsto\\)他の人も使うようになる。\n規模の経済：生産量が増えると、平均的な費用が低下する。\n\\(\\leadsto\\)単独で市場のニーズを満たすことができる。\n特にLLMの場合は初期投資が莫大\\(\\leadsto\\)新規参入が更に困難\n\n現在のLLMで重要なのは計算資源\\(\\times\\)データ量\\(\\times\\)モデルのサイズ\\(\\leadsto\\)資金＆時間\n\n\n\n\nKaplan ほか (2020)\n\n\n\n\n\nLLMの規模の発展\n\n\n\nGPT-3は1750億、GPT-4は5000億?以上\n\n\\(\\leadsto\\)先に行動する側に先行者利益 (first-mover advantage) がある。\n\nイーロン・マスクらがAIの開発モラトリアムを要求し、サム・アルトマンはAI規制の導入を主張\n\n一度、スタンダードになると（たとえ不便でも）それが利用され続ける。\n\n経路依存性 (path dependency)：過去の偶然の事象が長い期間に渡って影響すること\n\n日本は鉄道や原子力発電所などのインフラ輸出に力を入れている。\n\nネットワーク効果によって、その国のスタンダードになりうる。\n輸入国は特定の国への依存を避けるため、複数の国から導入したい。\n\n先進国による5Gにおけるファーウェイの排除は安全保障だけが理由ではない。\n\nネットワーク効果によってグローバル・スタンダードとなってしまう。\n中国に依存せざるを得なくなる、いわゆる技術覇権への懸念\n\nネットワーク効果\\(\\leadsto\\)みんながそのスタンダードを使うことが重要\\(\\leadsto\\)非国家アクターにもスタンダードを決める力\n\n私的権威 (private authority)：国家ではなく非国家アクター（企業や国際機関、テロリスト）が持つ権威(Hall と Biersteker 2002)\n国際標準化機構 (International Organization for Standardization: ISO) が様々な規格を定める。\nICANN (The Internet Corporation for Assigned Names and Numbers) がインターネットの運用を行っている。\n\n\n\n4.2.2 人工知能と環境\nLLMの開発には大規模な計算が必要\\(\\leadsto\\)莫大な電力消費と環境不可\n\n\n\nLLMの環境負荷\n\n\n\n\n4.2.3 人工知能と労働\nAIの発展によって雇用は減るのか？\n\nラッダイト運動：産業革命\\(\\leadsto\\)繊維産業の自動化\\(\\leadsto\\)熟練工の抗議\n\n自動化によって新しい雇用の創出＆効率的な生産による生活水準の向上\n1755-1802年の労働者の実質賃金は半減、生活環境の悪化\n\n\n\n\n\nAcemoglu と Restrepo (2020)\n\n\n製造の自動化とは異なり、LLM（やその他の生成AI）によって代替される職業は？(Eloundou ほか 2023)"
  },
  {
    "objectID": "machine_learning.html#機械学習の実践",
    "href": "machine_learning.html#機械学習の実践",
    "title": "人工知能の機械学習",
    "section": "5 機械学習の実践",
    "text": "5 機械学習の実践\nとりあえずデータに触れてみよう！\n\nGoogle Public Data Explorer\nGoogle Looker Studio\nTableau Public\n\nTableauが公開している公的データはこちら\n\n\n機械学習を初めとするデータ分析は様々な教材・資料がオンラインに無料で公開されている。\n人工知能（の基盤にある機械学習）の多くはPythonというプログラミング言語で実行\n\n制約付きではあるがGoogle Colaboratoryでオンラインで実行できる。\nPython自体も無料なので、自分のPCにインストールして実行できる。\n\n環境構築はちょっとめんどくさい\njupyter notebookやvisual studio codeなどが人気のある統合開発環境 (integrated development environment: IDE)\n\n\nパッケージをインストール・読み込む\\(\\leadsto\\)様々な分析\n\npandas：データの読み込み、処理\nmatpoltlib, seaborn：グラフの作成\nsicikit-learn：（深層学習を除く）機械学習\nstatsmodels：統計分析\n\n深層学習のライブラリとしてTensorFlow、PyTorch、kerasなど\n\nTensorFlow CoreのチュートリアルやTensorFlow HubのチュートリアルではGoogle Colaboratoryで試すことができる。\nまずは学習済みモデルを利用\n\nKaggleやSignate、Nishikaなどのデータ分析コンペ\n\n学生向けのイベントもあり\n就職活動でアピールできる（かも）"
  },
  {
    "objectID": "causal_inference_basic.html",
    "href": "causal_inference_basic.html",
    "title": "政策効果の検証：基礎",
    "section": "",
    "text": "近年、証拠に基づく政策立案 (evidence-based policy making: EBPM) の重要性が主張されている。\n\n行政官の経験や勘に頼らない意思決定\npolicy-based evidence makingの回避\nGoogle Trendsの傾向\n\n\\(\\leadsto\\)証拠とはなにか？\n\n政策の効果：ある政策によってどの程度、目標のアウトカムは変化したのか？\n\n政策効果と政策評価とは似て非なるもの。\n政策評価：目標をどの程度、実現したのか？\n例：訪日観光客\\(n\\)万人という目標の実現と、観光政策によって訪日観光客がどの程度増えたのかは別\n\nロジックモデル：政策資源の投入から政策成果までの論理的繋がりを可視化し、KPIを定めたもの。\n\nあくまで、論理を可視化するもので、それ自体が証拠ではない。\n\n\n\\(\\leadsto\\)この授業では証拠＝政策効果として議論する。\n\n\n\n\n\n\n警告\n\n\n\n講師は政策評価の専門家ではないので、他の授業（例えば、政策評価論や行政学系のもの）では異なる説明があると思われる。どちらが正しいというものではないことに留意。\n\n\n\n統計的因果推論の例\n統計的因果推論 (statistical causal inference)：原因と結果の関係（効果）を統計的に分析する\n\nマーケティングなどでも役に立つ\n事例研究をするときにも（データを使わなくても）役に立つ（かも）"
  },
  {
    "objectID": "causal_inference_basic.html#はじめに",
    "href": "causal_inference_basic.html#はじめに",
    "title": "政策効果の検証：基礎",
    "section": "",
    "text": "近年、証拠に基づく政策立案 (evidence-based policy making: EBPM) の重要性が主張されている。\n\n行政官の経験や勘に頼らない意思決定\npolicy-based evidence makingの回避\nGoogle Trendsの傾向\n\n\\(\\leadsto\\)証拠とはなにか？\n\n政策の効果：ある政策によってどの程度、目標のアウトカムは変化したのか？\n\n政策効果と政策評価とは似て非なるもの。\n政策評価：目標をどの程度、実現したのか？\n例：訪日観光客\\(n\\)万人という目標の実現と、観光政策によって訪日観光客がどの程度増えたのかは別\n\nロジックモデル：政策資源の投入から政策成果までの論理的繋がりを可視化し、KPIを定めたもの。\n\nあくまで、論理を可視化するもので、それ自体が証拠ではない。\n\n\n\\(\\leadsto\\)この授業では証拠＝政策効果として議論する。\n\n\n\n\n\n\n警告\n\n\n\n講師は政策評価の専門家ではないので、他の授業（例えば、政策評価論や行政学系のもの）では異なる説明があると思われる。どちらが正しいというものではないことに留意。\n\n\n\n統計的因果推論の例\n統計的因果推論 (statistical causal inference)：原因と結果の関係（効果）を統計的に分析する\n\nマーケティングなどでも役に立つ\n事例研究をするときにも（データを使わなくても）役に立つ（かも）"
  },
  {
    "objectID": "causal_inference_basic.html#交絡",
    "href": "causal_inference_basic.html#交絡",
    "title": "政策効果の検証：基礎",
    "section": "1 交絡",
    "text": "1 交絡\n\n1.1 ワクチンの効果\nデータ＝証拠ではない！\n\n新型コロナワクチンを例に\n\nワクチン接種者の方が重症者 (sever cases) が多い？\n\n\n\nIsraeli data: How can efficacy vs. severe disease be strong when 60% of hospitalized are vaccinated?\n\n\n\\(67.5%\\)の人はワクチンを打っていれば重症化しなかった？\n\n\n\nIsraeli data: How can efficacy vs. severe disease be strong when 60% of hospitalized are vaccinated?\n\n\n\n有効性：\\((16.4 - 5.3)/16.4 \\approx 67.5\\%\\)\n\n世代で分けると有効性が変わる？\n\n\n\nIsraeli data: How can efficacy vs. severe disease be strong when 60% of hospitalized are vaccinated?\n\n\nワクチンを接種するかどうかは（パンデミック初期は）重症化のしやすさに影響を受けていた。\n\n\n\n\n\nワクチン接種と重症化の架空の例\n\n\n\n\n\n\n\n\n\nワクチン接種と重症化の架空の例\n\n\n\n\n\\(\\leadsto\\)原因（政策）の有無で結果の違いが生じていても、効果とは言えない！\n\n\n1.2 交絡\nなぜ、単純な比較をするだけでは正しく効果を計算できなかったのか？\n交絡 (confounding)：原因と関係し、結果にも影響するような第三の要因がある状況\n\nそのような要因を交絡因子 (confounder) や共変量 (covariate) と呼ぶ。\n\n\n\n\n交絡の可視化\n\n\n\n原因→結果の関係を知りたいけれど、原因↔︎交絡因子→結果の関係（バックドアパス）があるので、正確に分析できない。\n因果関係ではないけれど相関関係が生じていることを見かけの相関 (spurious correlation) と呼ぶ。1\n\n相関関係は因果関係の前提と言われることがあるが、そうではない点に注意。\n\n\n1 本来は無関係なものが相関している状況を指していた。どのような交絡の例があるだろうか？\n\\(\\leadsto\\)交絡を取り除かない限り、データから効果を示すことはできない。\n\n事例分析をする際も同様\n\nある政策を行った自治体とそうではない自治体\nある自治体がある政策を行う前と後"
  },
  {
    "objectID": "causal_inference_basic.html#ランダム化比較試験",
    "href": "causal_inference_basic.html#ランダム化比較試験",
    "title": "政策効果の検証：基礎",
    "section": "2 ランダム化比較試験",
    "text": "2 ランダム化比較試験\n理想：全く同じ人がワクチンを受けた場合と受けなかった場合に重症化するかどうかを比較する。\n\\(\\leadsto\\)不可能\n現実：同じような集団がワクチンを受けた場合と受けなかった場合に重症化するかどうかを比較する。\n\\(\\leadsto\\)どのようにして「同じような集団」を作るのか？\nシンプルかつ強力な方法としてのランダム化比較試験 (randomized controlled trial: RCT)\n\nRCT：対象をランダムに分割して、一方には原因を与え、他方には原因を与えず、集団の結果を比較する。\n\n\n\n\nRCTのイメージ\n\n\nRCTで交絡（バックドア・パス）を消す！\n\nランダムにワクチンを摂取すれば年齢などとは無関係なはず。\n\n\n\n\nRCTの可視化\n\n\n\n2.1 フィールド実験\nフィールド実験：現実世界にランダムに介入して、実際の行動の変化を分析\n\nA/Bテストを初めとするオンラインテスト\n実際に政策をランダムに試行する。\n\n開発経済学を中心にRCTが活用(Banerjee と Duflo 2012; Leigh 2020)\n\n貧困層が移住しないのは資金が足りないからなのか、情報が足りないからなのか？(Bryan, Chowdhury, と Mobarak 2014)\n\n\n\n\nBryan, Chowdhury, と Mobarak (2014)\n\n\n\n中等教育は経済的に豊かになるのか？(Duflo, Dupas, と Kremer 2021)\n\n\n\n\nDuflo, Dupas, と Kremer (2021)\n\n\n\nどのようなメッセージだと人々は投票へ行くのか？(Gerber, Green, と Larimer 2008)\n\n\n\n\nGerber, Green, と Larimer (2008)\n\n\n\n\n2.2 サーベイ実験\nサーベイ実験：世論調査（サーベイ）にランダムな項目を入れ、表明された意見の変化を分析(Song と 秦 2020)\nサーベイ実験は政治学や社会学を中心に利用\n\n人々は移民に関する事実を知ると寛容になるのか？(Alesina, Miano, と Stantcheva 2023; Barrera ほか 2020)\n\n人々は移民の割合などを過大に評価している。\n\n\n\n\n\nAlesina, Miano, と Stantcheva (2023)\n\n\n\n移民の事実に関する質問と再配分政策への意見に関する質問の順番をランダムにする。\n\n移民の事実に関する誤解に気づいた人は再配分に寛容になる？\n\n\n\n\n\nAlesina, Miano, と Stantcheva (2023)\n\n\n\n移民に関する情報を以下のうちから1つだけランダムに提示し、マリーヌ・ル・ペンへの支持を調査\n\n\nなにも示さない\nマリーヌ・ル・ペンの主張（事実ではない）\n事実\n2と3の両方\n\n\n\n\nBarrera ほか (2020)\n\n\n\n2.2.1 コンジョイント実験\nコンジョイント実験：2つ（以上）の選択肢を提示し、その要因をランダムに変化させ、どの要因が選択に影響を与えているのかを分析\n\n人々はどのような政策を重視して投票するのか？\n\n衆院総選挙、緊急解析！　データが明かした有権者の本音\nマニフェスト選挙を疑え：2021年総選挙の計量政治学\n\n\n\n\n\nコンジョイント分析の例\n\n\n\n\n\nコンジョイント分析の結果\n\n\n\n\n2.2.2 リスト実験\n社会的望ましさバイアス (social desirebility bias: SDB)：回答者は社会的に望ましい答えをしようとして本音を話さない傾向\nリスト実験：該当する項目の数を尋ねることでSDBを回避する実験手法\n\n人々はどの程度、人種差別をしているのか？(Kuklinski, Cobb, と Gilens 1997)\n\n\n\n\nKuklinski, Cobb, と Gilens (1997)\n\n\n\n知りたい項目が入っているものと、そうでないものをランダムに表示させ、該当数を尋ねる。"
  },
  {
    "objectID": "causal_inference_basic.html#自然実験",
    "href": "causal_inference_basic.html#自然実験",
    "title": "政策効果の検証：基礎",
    "section": "3 自然実験",
    "text": "3 自然実験\n自然実験 (natural experiment)：RCTではないがRCTと同じような状況\n\nナショナリズムの高揚は武力紛争に繋がるのか？(Bertoli 2017)\n\n\n\n\nBertoli (2017)\n\n\n\n政治的指導者の交代は民主化や平和に繋がるのか？(Jones と Olken 2009)\n\n\n\n\nJones と Olken (2009)\n\n\n\n\n\nJones と Olken (2009)\n\n\n\n女性医師による治療は死亡率に影響するのか？(Tsugawa ほか 2017)\n\n\n\n\nTsugawa ほか (2017)"
  },
  {
    "objectID": "causal_inference_basic.html#統計的仮説検定",
    "href": "causal_inference_basic.html#統計的仮説検定",
    "title": "政策効果の検証：基礎",
    "section": "4 統計的仮説検定",
    "text": "4 統計的仮説検定\n\n\n\n\n\n\n警告\n\n\n\n統計的仮説検定は非常に難しいので、分からなくても構わない。講師を含めてちゃんと理解できているか怪しい。\n\n\nRCTや自然実験であれば、因果効果の大きさは明らかにできる？\n\\(\\leadsto\\)偶然、（本来は効果がないはずなのに）2つのグループで差が出てしまった可能性\n統計的仮説検定：効果が現れたのが偶然ではないかどうかを判別する方法\n\n仮に本当は効果がないとする（帰無仮説: null hypothesis）\n本当は効果がないのに、効果があるように見える実際のデータが生じる確率（p値: p-value）を求める。\n\np値を求めるときには推定結果の不確実性を表す標準誤差 (standard error: SE) を用いる。\n\np値が予め設定しておいた値（例えば\\(5\\%\\)）を下回っている場合、統計的に有意であると呼ぶ。2\n\n本当は効果がないのに\\(5\\%\\)の確率で生じる結果が出たのだとしたら、もはや「効果がない」という前提がおかしいのではないか。\n\n\n2 効果の値を標準誤差で割ったものが、およそ\\(2\\)以上であれば\\(5\\%\\)有意水準で統計的に有意である。\\(\\leadsto\\)とりあえず、統計的に有意でなければ効果があると強く主張できない。\n\n上記の代わりに信頼区間を求めて、信頼区間が0（などの基準点）を含まなかったら統計的に有意であると判断する方法もある。\n\n\n\n\n\n\n\n4.1 誤解・注意事項\n\np値が低ければ効果が大きい\n統計的に有意ではないから関係ない\np値は「効果がない」確率ではない\n\n\n\n4.2 問題点\np値が有意水準以下であるかどうかで二者択一の判断をすることが問題視\n\np-hacking：データや分析手法を変えて、統計的有意になるようにする\n出版バイアス：統計的に有意ではない結果 (null result) は出版されにくい。\nHARKing (hypothesizing after the results are known)：データ分析を行い、統計的に有意な結果から仮説を後付けする。\n\n\n\n\nBrodeur, Cook, と Heyes (2020)"
  },
  {
    "objectID": "causal_inference_basic.html#rctの限界注意点",
    "href": "causal_inference_basic.html#rctの限界注意点",
    "title": "政策効果の検証：基礎",
    "section": "5 RCTの限界・注意点",
    "text": "5 RCTの限界・注意点\n交絡がある限り、単純な比較では効果は分からない！\n\\(\\leadsto\\)RCTや自然実験のように、同じようなグループを作り出す工夫\n\n比較事例分析をする場合は、同じようだけど関心のある原因だけは異なるような事例を見つけてくる。\n\n\n5.1 サンプルの代表性\n無作為化比較試験：無作為に処置を割り当て\\(\\leadsto\\)効果を推定\n\n内的妥当性 (internal validity)：手元にあるデータの中で正しく因果推論できる\n\n無作為抽出 (random sampling)：特定の集団から一部を無作為に取り出すこと\n\n外的妥当性 (external validity) ：分析結果が分析に用いたデータ以外にも当てはまる\n\n（サンプルの）代表性：サンプルにおける属性（性別や年齢など）の割合が本当に知りたい集団と似ている。\nたとえ実験ではなくても世論調査などをする場合は無作為抽出は必要\n\n\n無作為割り当てができていても無作為抽出をしていなければ、分析結果が元々の集団に当てはまるかは分からない。\n\nもちろん、無作為抽出でも別の集団については当てはまるか分からない。\n\nオンラインのサンプルは市民を代表しているのか？\n\n（スペインとアメリカでは）Twitterユーザーは男性、都市部の住民、政治的に極端な人が多い、あるいは多くのツイートをしている(Barberá と Rivero 2015)\n（アメリカでは）調査会社のサンプルに比べてクラウドソーシングの参加者の属性は偏っている(Weinberg, Freese, と McElhattan 2014)\n\n\n\n\nWeinberg, Freese, と McElhattan (2014)\n\n\n\nただし、RCTの結果はどちらでも同じような傾向を持つ(Weinberg, Freese, と McElhattan 2014)\n\n\n\n5.2 一般均衡効果\nRCTでは集団全体から一部を取り出して、政策の有無を決定する。\n\\(\\leadsto\\)実際に政策を受けるのは全体から見るとごく一部\n政策として集団全体に実施した場合は、RCT通りの結果にならないかもしれない。\n\\(\\leadsto\\)集団全体における効果（一般均衡効果）が生じる。\n\n職業訓練や教育が賃金を上げるとしても、全員がプログラムを受けるとその効果は相殺？\n\n効果が波及する場合：RCTは適切に政策の効果を推定できない。\n\n\n5.3 実行可能性\nRCTや自然実験は因果推論における強力な手法だが、実行可能？\n\n多くの場合、個人を対象とするミクロな分析\n\n投票行動や消費者行動とは親和性が高いが、国家の行動や状態を分析することは困難\n\n処置が倫理的に問題がある可能性3\n\n嘘の情報や心理的に負担となる情報を与える。\n資金やトレーニングの提供など一部の人に有利（不利）なものかも\n\n高額な資金が必要かも\n\nサーベイ実験の場合、オンラインのクラウドソーシングのサービス4を利用すれば比較的安価に行える。\n調査会社のサンプルプールを利用する場合は高額\nフィールド実験の場合は運営費用＆現地のパートナーを確保\n\n（特にサーベイ実験の場合）表明選好に過ぎず、顕示選好ではないかも？\n\n質問への回答\\(\\neq\\)現実の政治的行動\n\n都合の良い自然実験はなかなか起こらない。\n\n3 実験を行う場合は大学の倫理審査委員会で審査を受け、認可される必要がある。4 Yahoo!クラウドソーシング、Amazon Mechanical Turk、LUCID Marketplaceなど。\\(\\leadsto\\)RCTや自然実験以外に政策効果を検証できないか？"
  },
  {
    "objectID": "big_data.html",
    "href": "big_data.html",
    "title": "デジタル化する社会",
    "section": "",
    "text": "警告\n\n\n\n日進月歩の分野なので、本章の内容はすぐに古いものになる（or既にそうであるかもしれない）点に注意。\n\n\n人工知能 (artificial intelligence) とは？\n\n\n\n\n\n\nターミネーター\n\n\n\n\n\n\n\nドラえもん\n\n\n\n\n\n\nコンピュータ（機械）が人間のように意思をもって、自律的に認識・判断・行動する？\n\n\\(\\leadsto\\)機械学習について学ぶことで（昨今、話題になっている）人工知能について理解する。\nなぜ機械学習 (machine learning) か？\n\n\n\n人工知能、機械学習、深層学習、生成AIの関係\n\n\n機械学習：データから一定のパターンを機械（パソコン）が学習し、予測をする。\n近年の人工知能\\(\\approx\\)機械学習のブレイクスルー\n\nビッグデータの利活用\n深層学習（およびその発展形）の発明\n豊富な計算資源\n\n\\(\\leadsto\\)特に（我々にとって）重要な1点目と2点目に焦点"
  },
  {
    "objectID": "big_data.html#はじめに",
    "href": "big_data.html#はじめに",
    "title": "デジタル化する社会",
    "section": "",
    "text": "警告\n\n\n\n日進月歩の分野なので、本章の内容はすぐに古いものになる（or既にそうであるかもしれない）点に注意。\n\n\n人工知能 (artificial intelligence) とは？\n\n\n\n\n\n\nターミネーター\n\n\n\n\n\n\n\nドラえもん\n\n\n\n\n\n\nコンピュータ（機械）が人間のように意思をもって、自律的に認識・判断・行動する？\n\n\\(\\leadsto\\)機械学習について学ぶことで（昨今、話題になっている）人工知能について理解する。\nなぜ機械学習 (machine learning) か？\n\n\n\n人工知能、機械学習、深層学習、生成AIの関係\n\n\n機械学習：データから一定のパターンを機械（パソコン）が学習し、予測をする。\n近年の人工知能\\(\\approx\\)機械学習のブレイクスルー\n\nビッグデータの利活用\n深層学習（およびその発展形）の発明\n豊富な計算資源\n\n\\(\\leadsto\\)特に（我々にとって）重要な1点目と2点目に焦点"
  },
  {
    "objectID": "big_data.html#ビッグデータ",
    "href": "big_data.html#ビッグデータ",
    "title": "デジタル化する社会",
    "section": "1 ビッグデータ",
    "text": "1 ビッグデータ\nインターネット空間の拡大やセンシング技術の向上（スマートフォン、衛星写真）により、ビッグデータを収集することができる。\n\nビッグデータ：人間の様々な活動が粒度の高い（従って大規模な）データとして記録される。\nインターネットはそのようなデータを生み出す最初の空間だったが、最近ではインターネットに限られない。\n\n\\(\\leadsto\\)ビッグデータの特徴は大規模であること自体ではなく、粒度 (granularity) が高い（データが細かい）ことである。\n\n多様性 (variery) ：国レベルではなく地方自治体、個人レベル\n\n小さいレベルのデータから全体を作ることはできるが、その逆ではない。\n\n速度 (velocity) ：年単位ではなく月単位、分単位\n\n一定の間隔や一時的なデータ収集ではなく、always-onが理想である。\n\n量 (volume) ：多様性と速度の結果としての大規模データ\n\n\\(\\leadsto\\)ビッグデータを解析できる機械学習（特に深層学習）の登場により、ビッグデータの価値が生まれ始めている。\n\n1.1 ビッグではないデータ\n伝統的なデータは分析レベルが荒いデータである。\n\nUCDPの紛争データ\nV-Demの政治体制データ\n東大・朝日の世論調査\n\n多くの場合、\n\n国レベルに集計したり、一部の個人のみを対象\n毎年、イベントごとなど特定の時点のみを対象\n\nとしている。\n\n\n1.2 地理情報システム\nGPS付きスマートフォンのデータにより個人の位置情報がほぼリアルタイムで計測できる。\n\n外出者の数や移動経路が分かり、感染症対策に利活用できる。\n\n地理情報システム (geospatial information system: GIS) の発展・普及によって地理空間データの利活用が進んでいる。\n人工衛星の写真から経済発展や森林破壊の度合いを測定することができる。\n\\(\\leadsto\\)リモート・センシングによりこれまでアクセスできなかったデータを取得できる。\n\n統計が怪しい、取ることのできない地域のデータ\n行政単位よりも細かい地域区分でデータ\n\n\n\n\n\n\n\n\n\n\n\n\nSatellite images of the earth at night reveal the pace of economic growth and much more\n\n\n\n通話履歴から個人の（従って地域の）豊かさを予測することができる。\n\nルワンダ最大の携帯電話会社の協力を得て分析を行った。\n\n\n\n\nBlumenstock, Cadamuro, と On (2015)\n\n\n街中にある監視カメラと画像認識技術を組み合わせることで、犯人の迅速な逮捕や犯罪防止に役立っている。\n\nプライバシーの侵害の懸念はある。\n中国は監視技術を外国に輸出している。\n\nGISを（無料で）使えるサービスがある。\n\nRESAS\njSTAT MAP\nQGIS\n\n\n\n\n\n\n\n1.3 企業データ\n株式保有のデータを用いて、株式ネットワークのデータを構築することができる。\n\\(\\leadsto\\)直接的だけでなく間接的に、どのような株主が、どのような企業を、どの程度接続しているのかが分かる。\n\n\n\n2020年のグローバルな株式ネットワーク\n\n\n\n間接的支配を含めると、中国政府は世界最大の株主である。\n一般的に販売されている金融商品の約9割が軍事企業や環境破壊企業に繋がっている。\n「隠れ株主」を探せ：米テスラ、サプライチェーンの「身体検査」\n\n\n\n1.4 デジタル・ヒューマニティーズ\n人文学（特に歴史学）にデジタル技術を取り入れている分野をデジタル・ヒューマニティ (digital humanity) と呼ぶ。\n電子書籍によって大量の書籍を電子的に処理することが可能になった。\n\nGoogle Ngram ViewerやNDL Ngram Viewerによって1800年ごろから書籍における単語の頻度を見ることができる。\n\n\n\n\n\n画像認識の技術を応用して日本史の資料のデジタル化が進んでいる。\n\nくずし字OCR\n江戸料理レシピ\n浮世絵顔データ"
  },
  {
    "objectID": "big_data.html#インターネット空間",
    "href": "big_data.html#インターネット空間",
    "title": "デジタル化する社会",
    "section": "2 インターネット空間",
    "text": "2 インターネット空間\n21世紀の特徴の1つはインターネット空間の登場と拡大である。\n\\(\\leadsto\\)情報通信コストが限りなく下がり、経済活動だけでなく言論空間もオンライン上に構築された。\n\n\n\nSalganik (2019)\n\n\nビッグデータという観点からすると、膨大な量のデータが日々、作られている。\n\nテキストデータ\n画像データ\n音声データ\n映像データ\n\n\\(\\leadsto\\)人工知能の誕生によって、はじめてビッグデータに価値が生まれ、インターネット空間が（さらに）変容しつつある。\nなぜGoogleは強いのか？\n\nGoogle Flu Trendsというインフルエンザに関する検索傾向からインフルエンザの感染を予測するサービスがあった（現在は中止）。\n\n\n\n\nIs ‘Google Flu Trends’ Prescient Or Wrong?\n\n\n\nGoogleトレンドで検索傾向を調べることができる。\n\nしかも、人々がアノテーション（情報の付加）をしてくれている。\n\n商品やお店のレビュー\n画像のタグ付け（画像つきツイート）、地理情報\n\n\n2.1 ソーシャル・ネットワーク\nデジタル・フットプリント（インターネット上の行動履歴）から個人的属性を予測できる。\n\\(\\leadsto\\)個人に焦点を当てた（パーソナライズした）マーケティングを行える。\n\nインターネットの広告、eコマースにおける推薦\n\n\\(\\leadsto\\)ユーザーは自由に情報を検索して、選択しているつもりでも、表示される情報は誘導されている。\nNetflixはデータを公開して予測コンペ (Netflix Prize) を行っていた。\n公開されたデータは匿名であるが、視聴履歴から個人を特定することができることが分かる。\n\n脱匿名化、再識別などと呼ぶ。\n\n\\(\\leadsto\\)政治信条や性的志向が判明する危険性がある。\nSNSは豊富な情報を持つビッグデータである。\n\n個人レベル\nalways-on\nテキスト、画像と繋がり（ネットワーク）\n\n\\(\\leadsto\\)政治信条や性的志向が暴露されてしまう危険性がある。\n\nとある研究ではFacebookの「いいね (like) 」を使って個人属性を予測した。\n\n\n\n\nKosinski, Stillwell, と Graepel (2013)\n\n\n\nケンブリッジ・アナリティカ社がFacebook上で選挙介入を行ったと指摘されている。\n\n\n\n2.2 SNS上のコミュニティ\n人々は同じ意見を持っている人同士で繋がる傾向をホモフィリーと呼ぶ。\n\nトランプのフォロワーはクリントンのフォロワーと繋がりにくい。\n\n\n\n\nJournalists and Trump voters live in separate online bubbles, MIT analysis shows\n\n\n\n同じ党派性のアカウントをフォロー、リツイートする。\n\n\n\n\nHalberstam と Knight (2016)\n\n\n\n\n\nHalberstam と Knight (2016)\n\n\n同質的なコミュニティで意見が反射、増幅して信念が強化されるエコー・チェンバーが生じる。\n\n人種差別についてリベラルでしか議論されない。\n移民や銃については両方で議論されているが、繋がってはいない。\n\n\n\n\nJournalists and Trump voters live in separate online bubbles, MIT analysis shows\n\n\nSNSがパーソナライズされる（フォローの推薦）ことで投稿内容やユーザーが限定される。\n\n2023年3月31日に公開されたTwitterの「おすすめ」アルゴリズム\n\n\\(\\leadsto\\)（本人の意図によらず）見たくない情報がSNS上から除去されるフィルター・バブルができる。\n\n\n\nJournalists and Trump voters live in separate online bubbles, MIT analysis shows\n\n\n\n共和党支持者は気候変動は嘘であると信じ、民主党支持者は遺伝子組み換え食品を危険だと思っている。\n教育水準が高ければ、科学的知識を身につけるとは限らない。\n\n\n\n\nThe More Education Republicans Have, the Less They Tend to Believe in Climate Change\n\n\nホモフィリーが正しいのだとすれば、SNS上の繋がりから政治的イデオロギーも分かる。\n\nSNS上を通じて世論や分極化をリアルタイムに観測できる。\nSNS上の情報で個人の政治的傾向が分かってしまう。\n\n\n\n\nBarberá ほか (2015)\n\n\n\n\n2.3 SNSと分極化・分断\n分極化 (polarization)：社会において意見（特にイデオロギー）が分断し、それぞれ極端になっていく現象\n\\(\\leadsto\\)インターネットは分極化を加速させるのか？\n稲増 (2022, 第5章)によれば、そこまでの影響力は大きくない。\n\nアルゴリズムによる表示 (exposed) よりも、自身の選択 (selected) の方が異なるイデオロギーの記事にアクセスしにくい（あるいは大差はない）。\n\n\n\n\nbakshy2015\n\n\n\nニュースアグリゲーターよりもSNSなどのほうが多様な意見のサイトにアクセスしやすい。\n\n\n\n\nFlaxman, Goel, と Rao (2016)\n\n\n\nニュースアグリゲーターやSNSは異なる意見のサイトにアクセスしやすい。\n\n\n\n\nFlaxman, Goel, と Rao (2016)\n\n\n\\(\\leadsto\\)アルゴリズムによる分断よりも、自らの選択？\n異なる意見・民族の人との接触は偏見を減らす(Paluck, Green, と Green 2019)。\n\n単なる接触だけでは不十分かも？\n\n\n\n2.4 中国によるSNS検閲\n中国ではTwitterなどは利用できないが、類似のサービスが利用されているが、検閲されているかもしれない。\n\\(\\leadsto\\)とある研究によって、情報を隠すという検閲により、隠したい中国政府の意図が分かってしまった。\nどうやって検閲を見つけるのか？\n\n人力検閲で削除される前にスクレイピングする。\n実際に中国のSNSアカウントを作り、投稿する。\n実際に中国のSNSサービスを作り、マニュアルを見る。\n\n自動検閲される確率は（2013年時点では）ほとんどない。\n\n\n\nKing, Pan, と Roberts (2014)\n\n\n中国で検閲されやすい内容は\n\nデモや集会に繋がる行動\n検閲の批判\nポルノグラフィー\n\nに関するものである。\n\n\n\nKing, Pan, と Roberts (2013)\n\n\n検閲される確率は政府に対して肯定的であるか批判的であるかは「関係がない」。\n\n天安門事件に関する投稿だからといって削除されるとは限らない。\n\n\n\n\nKing, Pan, と Roberts (2013)\n\n\n中国のSNSでは五毛党 (50 Cent Party) が世論誘導 (astroturfing) を行っていると考えられている。\n\nとある地区の五毛党のリストがリークした。\n\n\\(\\leadsto\\)機械学習によって五毛党のアカウントを予測し、それらの投稿の内容も分類できる。\n五毛党は協調して投稿している。\n五毛党は外国の批判や論争への参加はしていない。\n\n愛国心を煽る表現\n政府の政策の紹介\n論争的ではない政府の称賛\n\n\\(\\leadsto\\)政府の意見を広めるというより、不都合な情報から目を逸らそうとしているのでは？\n\n\n\nKing, Pan, と Roberts (2017)\n\n\n\n\n\nKing, Pan, と Roberts (2017)\n\n\n\n\n2.5 オンライン実験\nA/Bテストとはランダムに異なるウェブサイトを表示し、収益の高いウェブサイトを見つける実験のことである。11 実験については統計的因果推論において解説する。\n\nオバマ元大統領は選挙資金の寄付を受け付けるサイトのデザインでA/Bテストを行い、約6000万ドルの寄付増加に繋がったと言われている。\n\n\n\n\nあの大統領も140%の成果改善。アメリカ大統領とA/Bテストの意外な関係\n\n\nオンライン上では（しばしば利用者が知らないうちに）実験が行われている。\n\nFacebookの選挙実験では友人が投票に行ったことを知ると、投票率が上がることが分かった。\n\n\n\n\nBond ほか (2012)\n\n\n\nFacebookの感情実験ではTL上にネガティブな投稿が表示されなくなると、ポジティブな投稿が増える（その逆も然り）ことが分かった。\n\n\n\n\nKramer, Guillory, と Hancock (2014)\n\n\n\n\n2.6 影響工作\n影響工作 (influence operation)：フェイクニュースなどを通じて世論に影響を与えようとする行動\n\\(\\leadsto\\)インターネット空間ではボットによる情報提供が容易に(Lazer ほか 2009; Ferrara ほか 2016)。\n\n2016年のアメリカ大統領選ではトランプ支持のツイートを（特に接戦州で）ボットが共有\nイギリスのEU離脱投票の際にも賛成派と反対派のボットが情報を拡散\n\n\n\n\nGorodnichenko, Pham, と Talavera (2021)\n\n\n\n\n\nGorodnichenko, Pham, と Talavera (2021)\n\n\n信頼のできないボット（赤い点）が特定のユーザーをリツイートしている。\n\n\n\nXu と Sasahara (2022)\n\n\n\n信頼のできないボットは陰謀論者をリツイート\nスーパスプレッダーとなるボット\n\nとある研究によれば、フェイクニュースは正しいニュースよりもリツイートされやすく、早く、広く拡散する。\n\n\n\nVosoughi, Roy, と Aral (2018)\n\n\nただし、インターネットを含めてマスメディアの影響を過大評価するべきではない。\n\nインターネットではない伝統的メディアでも同様の問題は起こっている。\n\nオフラインでも党派性に従ってニュースを消費している(Gentzkow と Shapiro 2011; Martin と Yurukoglu 2017)。\n\nメディアの効果に関するサーベイとして 稲増 (2022) を参照。\n\n\n\n2.7 新しい戦場\n軍事行動や社会活動が情報化 \\(\\leadsto\\)宇宙空間とインターネット空間も戦場？\n\n偵察衛星や通信衛星、GPSは軍事行動において必要不可欠\n社会的インフラへのサイバー攻撃やフェイクニュースの拡散によって社会を混乱させる？\n\n\\(\\leadsto\\)問題は攻撃側をどのように特定するのか、物理的な報復手段が許されるのか"
  },
  {
    "objectID": "big_data.html#資源としてのデータ",
    "href": "big_data.html#資源としてのデータ",
    "title": "デジタル化する社会",
    "section": "3 資源としてのデータ",
    "text": "3 資源としてのデータ\n機械学習が調理法だとすれば、データは食材と言える。\n\\(\\leadsto\\)近年の機械学習の発展（後述）により、データの価値が発見（21世紀の資源と呼ばれることも）\n\nデータそれ自体に価値があるわけではない。\n\n適切な調理法（と下ごしらえ）がなければ宝の持ち腐れ。\n\n\n機械学習において、データの量が多いことは性能の向上に繋がるスケーリング則が発見されている。\n\n\n\nKaplan ほか (2020)\n\n\n\\(\\leadsto\\)資源としてデータは足りるのか？\n質の良いテキストデータは近いうちに枯渇する可能性が指摘されている。\n\n非デジタル情報のデジタル化？\nネットユーザーの拡大？\nAI利用者の入力データの利用？"
  },
  {
    "objectID": "causal_inference_advanced.html#統制",
    "href": "causal_inference_advanced.html#統制",
    "title": "政策効果の検証：発展",
    "section": "1 統制",
    "text": "1 統制\n\n1.1 マッチング\n\n\n1.2 回帰分析"
  },
  {
    "objectID": "causal_inference_advanced.html#回帰不連続デザイン",
    "href": "causal_inference_advanced.html#回帰不連続デザイン",
    "title": "政策効果の検証：発展",
    "section": "2 回帰不連続デザイン",
    "text": "2 回帰不連続デザイン"
  },
  {
    "objectID": "causal_inference_advanced.html#差分の差",
    "href": "causal_inference_advanced.html#差分の差",
    "title": "政策効果の検証：発展",
    "section": "3 差分の差",
    "text": "3 差分の差"
  },
  {
    "objectID": "causal_inference_advanced.html#合成統制法",
    "href": "causal_inference_advanced.html#合成統制法",
    "title": "政策効果の検証：発展",
    "section": "4 合成統制法",
    "text": "4 合成統制法"
  },
  {
    "objectID": "causal_inference_advanced.html#操作変数法",
    "href": "causal_inference_advanced.html#操作変数法",
    "title": "政策効果の検証：発展",
    "section": "5 操作変数法",
    "text": "5 操作変数法"
  },
  {
    "objectID": "causal_inference_advanced.html#観察データの限界注意点",
    "href": "causal_inference_advanced.html#観察データの限界注意点",
    "title": "政策効果の検証：発展",
    "section": "6 観察データの限界・注意点",
    "text": "6 観察データの限界・注意点"
  },
  {
    "objectID": "causal_inference_advanced.html#事例研究",
    "href": "causal_inference_advanced.html#事例研究",
    "title": "政策効果の検証：発展",
    "section": "7 事例研究",
    "text": "7 事例研究"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "はじめに",
    "section": "",
    "text": "土井翔平が担当する北海道大学公共政策大学院 (HOPS)の技術政策学（データ科学編）の講義レジュメです。受講生はこのサイトもしくはpdf版を参照して、授業に望んでください。"
  },
  {
    "objectID": "index.html#目標",
    "href": "index.html#目標",
    "title": "はじめに",
    "section": "1 目標",
    "text": "1 目標\n様々な科学技術の中でも近年、発展が目覚ましいデータ科学について学ぶ。11 講師はデータ科学を用いた国際関係の分析を行っている。\n\n科学技術のための公共政策：データ科学にはどのような弊害があり、それらに対して社会はどのように対応するべきなのか？\n公共政策のための科学技術：データ科学はにはどのような利点があり、それらをどのように社会のために利活用するべきなのか？\n\n\\(\\leadsto\\)代表的なデータ科学の手法について、その概要と長所・短所を学ぶ。"
  },
  {
    "objectID": "index.html#トピック",
    "href": "index.html#トピック",
    "title": "はじめに",
    "section": "2 トピック",
    "text": "2 トピック\nデータ科学の中でも機械学習と統計的因果推論を扱う。\n\n機械学習（いわゆる人工知能）：多様なデータからパターンを学習し、予測や生成を行う。\n\n深層学習（ディープラーニング）は機械学習の一手法\n\n統計的因果推論：人間や社会に関するデータから因果関係、政策効果を推定する。\n\n時間が許せば、これらを実際に行うためのプログラミング言語であるPythonを用いた実習を行う。\n\nノートPCを持参する。\nGoogleアカウントを作成する。\n\nGoogle Colaboratoryを使用する。\n自身のPCにPython環境が構築されている場合は不要\n\nMDSセンターの教材を用いてPythonの学習をすることを強く推奨する。2\n\n2 いずれ、情報Iを高校で学習した人々が社会に進出してくる。"
  },
  {
    "objectID": "index.html#授業の進め方",
    "href": "index.html#授業の進め方",
    "title": "はじめに",
    "section": "3 授業の進め方",
    "text": "3 授業の進め方\nMoodleを参照すること。"
  },
  {
    "objectID": "index.html#参考書",
    "href": "index.html#参考書",
    "title": "はじめに",
    "section": "4 参考書",
    "text": "4 参考書\n\n機械学習：Ng と Soo (2019), 久野 と 木脇 (2018), 北川 ほか (2023)\n統計的因果推論：中室 と 津川 (2017), 伊藤 (2017), 松林 (2021)\n\nデータ科学については優良な資料がオンラインで無料で公開されているので、各自で調べて参照すること。"
  }
]